import { Project } from '../types';

export const projects: Project[] = [
  {
  id: "deepfake-detection-system",
  title: "Detection of Face-Swap Based Deep Fake Videos",
  description: "A state-of-the-art multi-modal deepfake detection system that integrates computer vision and deep learning to achieve robust video authenticity verification. The system uses an ensemble of specialized CNNs and a Bidirectional LSTM for temporal fusion, enabling highly accurate detection of manipulated video content. It analyzes multiple modalities including texture, edge, and frequency domains to identify deepfake artifacts with high precision, ensuring reliable and interpretable fake detection results.",
  image: "images/deepfake.png",
  technologies: [
    "Python",
    "Deep Learning",
    "Computer Vision",
    "TensorFlow",
    "Keras",
    "OpenCV",
    "NumPy",
    "Pandas",
    "RetinaFace",
    "Fast Fourier Transform (FFT)",
    "Contrast Limited Adaptive Histogram Equalization (CLAHE)",
    "Canny Edge Detection",
    "Sobel Filters",
    "Bidirectional LSTM",
    "MesoNet",
    "Feature Fusion",
    "Model Optimization",
    "Data Preprocessing",
    "Multi-Modal Learning",
    "Temporal Sequence Analysis"
  ],
  githubUrl: "https://github.com/Deekshithshaiva05/Detection-of-Face-Swap-Based-on-DeepFake-Videos.git",
  featured: true,
  details: "The Ultimate DeepFake Detection System is a high-performance, multi-modal AI framework designed for accurate video authenticity verification. It combines advanced computer vision techniques with deep learning to analyze visual and temporal patterns in videos, effectively identifying synthetic manipulations. The system processes input videos from datasets like FaceForensics++, DFDC, Celeb-DF, and custom sources. Using RetinaFace, it extracts and aligns facial regions, followed by standardized cropping at 224×224 resolution. Multiple modalities are then analyzed: CLAHE enhancement for texture irregularities, edge detection (Canny + Sobel) for boundary consistency, and FFT transformation for frequency-domain artifacts. Each modality is processed through a dedicated CNN model that outputs probability scores, forming temporal sequences analyzed by a Bidirectional LSTM for final decision-making. This fusion model achieves 88.75% overall accuracy with a 96.16% AUC, significantly outperforming individual modality networks. Designed for interpretability and efficiency, the architecture supports real-time inference and confidence scoring, ensuring robustness across varied datasets and compression levels. The system’s modular design allows easy integration as a standalone application, research framework, or API service. Its innovation lies in multi-modal fusion, temporal consistency analysis, and confidence calibration, providing a reliable, interpretable, and scalable solution for modern video forensics. Through advanced CNN architectures, attention mechanisms, and optimized regularization strategies, the model minimizes overfitting while maximizing generalization, making it suitable for real-world deployment in detecting deepfakes generated by GANs, autoencoders, and commercial manipulation tools."
  },
  {
    id: 'car-price-prediction',
    title: 'CAR PRICE PREDICTION ANALYSIS',
    description: 'Accurately predicting the price of a used car is a complex task due to the numerous factors involved. Manual methods or basic tools often result in significant errors, either undervaluing or overvaluing vehicles.This inconsistency poses challenges for both buyers and sellers, impacting market trust and efficiency.',
    image: 'images/Car.png',
    technologies: ['Python','XGBoost','Random Forest','Linear Regression','Flask','Pandas','NumPy','Machine Learning','Version Control(Git,GitHub)','HyperParameter Tuning','CatBoost Regressor','Forntend development(HTML,CSS,JS)'],
    githubUrl: 'https://github.com/Deekshithshaiva05/USED_CAR_PRICE_PREDICTION.git',
    featured: false,
    details: 'The process of buying and selling used cars has become increasingly dynamic, with buyers seeking value for money and sellers aiming for competitive pricing.Factors such as car brand, model, year of manufacture, mileage, and overall condition significantly influence the market value of a vehicle.Accurate price estimation plays a vital role in bridging the gap between buyers and sellers, ensuring fair and transparent transactions.Machine learning techniques offer innovative solutions by analyzing these factors to predict car prices with high accuracy.The CatBoosting Regressor achieves the highest accuracy with an R2R^2 R2-Score of 0.9437, followed closely by XGBoost (0.9414) and Random Forest (0.9400). ',
  },
  {
  id: "medicine-recommendation-system",
  title: "Medicine Recommendation System",
  description: "A machine learning-based system that recommends the most suitable medicines based on symptoms and medical conditions, helping healthcare professionals in quick decision-making. The system analyzes user inputs such as symptoms, medical history, and other relevant factors, and leverages a trained machine learning model to suggest potential medications. This tool can help doctors and pharmacists make more informed decisions, improving diagnosis efficiency and reducing human error in treatment planning. By utilizing a comprehensive database of medicines, dosages, and side effects, the system also offers alternative recommendations in case of contraindications or allergies, ensuring safer healthcare practices.",
  image: "images/medicine.png",
  technologies: [
    "Python",
    "Machine Learning",
    "Flask",
    "scikit-learn",
    "Pandas",
    "NumPy",
    "Data Analysis",
    "Data Preprocessing",
    "Feature Engineering",
    "Model Training and Evaluation",
    "Natural Language Processing (NLP)",
    "Model Deployment (Flask for web-based application)",
    "Hyperparameter Tuning",
    "Data Visualization",
    "Version Control (Git)"
  ],
  githubUrl: "https://github.com/Deekshithshaiva05/Medicine-prediction.git",
  featured: false,
  details:"This project involves developing a machine learning model that suggests the most appropriate medicines based on a users symptoms, medical conditions, and personal health data. The system is trained on a large dataset of historical medical records, including information about symptoms, diagnoses, treatment protocols, and prescribed medications. By analyzing this data, the model identifies patterns and correlations, allowing it to recommend the best course of action for the user. The system allows users to input their symptoms and medical conditions through an intuitive web interface built with Flask, which then processes this input and generates tailored medicine recommendations. The model not only suggests the most appropriate medications but also provides dosage information, potential side effects, and possible drug interactions, ensuring a safer and more informed decision-making process. Key features of the system include personalized medicine recommendations based on symptoms and medical history, real-time updates as new medical knowledge becomes available, and alerts for potential drug interactions. The user-friendly interface allows for easy symptom entry, while the system remains scalable to support a broader range of conditions and treatments. Being data-driven, it relies on accurate machine learning algorithms to maintain reliability. The recommendation system leverages scikit-learn for training various models, and uses Pandas and NumPy for efficient data handling. To ensure high accuracy, preprocessing steps like normalization and imputation are applied. The application also includes a feedback loop where healthcare professionals can evaluate suggestions, which helps refine future predictions. By integrating real-time medical data and maintaining adaptability, this solution supports faster diagnoses and reduces human error. The backend is secured, maintains patient confidentiality, and is designed for scalability in real-world clinical environments, making it a reliable asset for digital healthcare advancement.",
  },
  {
  "id": "innovbyte-ai-prompt-engine",
  "title": "InnovByte AI — Prompt Review & Enhancement Engine",
  "description": "A real-time prompt validation and enhancement system designed to analyze, sanitize, and optimize user prompts for safer, more accurate, and higher-quality LLM responses. InnovByte AI ensures every prompt is grammatically sound, contextually complete, and free from unsafe content before dispatching it to large language models.",
  "image": "images/innovbyte_ai.png",
  "technologies": [
    "Python",
    "Flask",
    "Natural Language Processing (NLP)",
    "Large Language Models (LLMs)",
    "OpenAI API",
    "Gemini API",
    "Ollama",
    "DeepSeek",
    "Voice Recognition (Speech-to-Text)",
    "Text Classification",
    "Prompt Engineering",
    "JSON Schema Design",
    "COSTAR Framework",
    "ISTVON Framework",
    "Grammar Correction",
    "Safety Filtering",
    "Web Development",
    "Frontend (HTML, CSS, JS)",
    "REST API Integration"
  ],
  "githubUrl": "https://github.com/Deekshithshaiva05/InnovByte-AI",
  "featured": true,
  "details": "InnovByte AI is a real-time web application that automatically reviews, enhances, and structures prompts before they are processed by large language models. Developed during a 24-hour hackathon at MITM Mysore by Team InnovByte (Deekshith N, Vinay S Dhakshath UK, and Prajwal M), it acts as a preprocessing safety and quality assurance layer for LLM inputs. The system validates grammar, detects unsafe or confidential content, checks for completeness, and then categorizes each prompt into one of three outcomes: BLOCK, NEEDS_FIX, or ALLOW. For prompts requiring enhancement, the system returns an improved version enriched with structured metadata using the COSTAR or ISTVON frameworks — ensuring better LLM comprehension and output consistency. Key features include multi-input support for text and voice prompts, automatic grammar correction, safety and confidentiality filtering, and structured enrichment for improved interpretability. It classifies prompts into BLOCK (unsafe), NEEDS_FIX (incomplete), or ALLOW (ready to process) categories. The COSTAR/ISTVON enrichment feature generates structured JSON prompts that define context, objectives, tone, and deliverables, enabling consistent and accurate AI responses. The system supports dispatching enhanced prompts to multiple LLM backends including OpenAI, Gemini, Ollama, DeepSeek, and ESC, while also allowing users to export and reuse structured JSON outputs easily. The workflow involves user input, grammar and safety checks, enhancement or validation, JSON generation, and LLM backend selection. COSTAR schema ensures clarity and precision by defining Context, Objective, Style, Tone, Audience, and Response, while ISTVON automates structured AI orchestration with Instructions, Source Data, Tools, Variables, Outcome, and Notification layers. InnovByte AI enhances LLM performance through structured, context-aware prompting, reduces hallucinations, ensures multi-LLM compatibility, and improves response reliability. Supported backends include rule-based, OpenAI, Gemini, Ollama, DeepSeek, and ESC engines. The roadmap focuses on context-aware safety classifiers, enterprise blocklist customization, analytics dashboards, seamless API integrations, and team management with audit trails. Built during a 24-hour hackathon at MITM Mysore, the project by Deekshith N, Vinay S Dhakshath UK, and Prajwal M emphasizes safe, interpretable, and structured AI prompt engineering for multi-agent and enterprise-level applications."
  },

  {
  "id": "email-spam-detection-tool",
  "title": "Email Spam Detection Tool",
  "description": "A lightweight yet powerful machine learning-based web application built with Flask that classifies email messages as Spam or Not Spam. The system leverages TF-IDF vectorization and a trained scikit-learn model to ensure high-accuracy real-time predictions. Designed with a modern, responsive frontend, it offers an intuitive interface for users to test email messages effortlessly.",
  "image": "images/email_spam.png",
  "technologies": [
    "Python",
    "Flask",
    "Machine Learning",
    "scikit-learn",
    "TF-IDF Vectorization",
    "Pickle",
    "HTML",
    "CSS",
    "JavaScript",
    "Bootstrap",
    "Tailwind CSS",
    "Natural Language Processing (NLP)",
    "Text Preprocessing",
    "Model Deployment",
    "Web Development",
    "Gunicorn"
  ],
  "githubUrl": "https://github.com/Deekshithshaiva05/Email-Spam-Classification.git",
  "featured": false,
  "details": "The Email Spam Detection Tool is a machine learning-powered Flask web application designed to automatically classify email content as Spam or Not Spam. Built using Python and scikit-learn, the model employs a TF-IDF vectorizer to convert raw email text into numerical feature representations, allowing effective pattern recognition and classification. The training process utilizes a Naïve Bayes or Logistic Regression algorithm—chosen for their high precision in text-based classification—achieving an overall accuracy of 97.6% on test data. The backend, implemented in Flask, serves predictions via an interactive web interface where users can paste or type any email message to instantly receive spam detection results along with prediction confidence levels. \n\nThe project’s modular design ensures seamless deployment and scalability. Model and vectorizer files are serialized using Pickle, enabling quick loading and inference without retraining. The frontend is built with HTML, CSS, and JavaScript, featuring a responsive design enhanced with Bootstrap/Tailwind for a clean, user-friendly experience. The system can be deployed easily on cloud platforms such as Render, Railway, or Heroku using Gunicorn as the WSGI server. \n\nIts simplicity, interpretability, and efficiency make it an excellent example of applying Natural Language Processing (NLP) and Machine Learning for cybersecurity and email filtering automation. The application structure includes separate directories for templates and static assets, promoting maintainability and readability. Through this project, end-users gain an instant and reliable spam classification tool, while developers can extend it further with advanced models, dataset expansion, or API integration."
  },
  {
  "id": "isl-recognition-3d-animation",
  "title": "Indian Sign Language Recognition and 3D Animation System",
  "description": "An AI-powered solution designed to recognize Indian Sign Language (ISL) gestures and translate them into animated 3D visualizations, bridging the communication gap for the deaf and hard-of-hearing community. The project integrates computer vision, machine learning, and 3D animation to promote inclusivity and accessibility through technology.",
  "image": "images/isl_3d_animation.png",
  "technologies": [
    "Python",
    "Machine Learning",
    "Computer Vision",
    "Blender",
    "AI Models",
    "3D Animation",
    "OpenCV",
    "TensorFlow",
    "MediaPipe",
    "Gesture Recognition",
    "Human-Computer Interaction"
  ],
  "githubUrl": "https://lnkd.in/g-iDDdEr",
  "featured": true,
  "details": "✨ From Idea to Impact — in just 24 hours! The Indian Sign Language (ISL) Recognition and Animation System was developed during Symbiot-2025, a national-level hackathon held on May 8–9 at Vidyavardhaka College of Engineering, Mysuru. Our team, AI PIONEER'S — consisting of Deekshith N, Syed Farhaan, Prashanth Singh, and Shamanth M — took on the challenge of creating a meaningful AI solution aimed at improving communication accessibility for the deaf and hard-of-hearing community. The system detects ISL gestures using computer vision and interprets them in real time, translating the gestures into corresponding 3D animations performed by a virtual human avatar. This enables seamless two-way communication between sign language users and others. The technical implementation combines Python, AI-based gesture recognition models, and Blender for realistic 3D animation rendering. The prototype demonstrates words such as 'Hello' through accurate hand-tracking and animation synchronization. The 24-hour hackathon experience included brainstorming, designing, coding, and presenting a working prototype that showcased the potential of AI-driven accessibility tools. This project marks a step toward inclusive communication technologies powered by AI and creativity. Built for Symbiot-2025 at VVCE Mysuru, the project highlights teamwork, innovation, and social impact — proving that meaningful tech for good can emerge even within tight deadlines.",
  "eventInfo": {
    "eventName": "Symbiot-2025",
    "eventType": "National-Level Hackathon",
    "eventDates": "May 8–9, 2025",
    "location": "Vidyavardhaka College of Engineering, Mysuru",
    "teamName": "AI PIONEER'S",
    "teamMembers": ["Deekshith N", "Syed Farhaan", "Prashanth Singh", "Shamanth M"]
  },
  "hashtags": [
    "#Hackathon",
    "#Symbiot2025",
    "#IndianSignLanguage",
    "#AI",
    "#Inclusion",
    "#3DAnimation",
    "#Teamwork",
    "#MachineLearning",
    "#Blender",
    "#Mysuru",
    "#Accessibility",
    "#TechForGood"
  ]
  },


  
];